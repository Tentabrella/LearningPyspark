{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create from RDD\n",
    "some_rdd = sc.parallelize([Row(name = 'John', age = 19),\n",
    "                          Row(name = 'Bob', age = 21)])\n",
    "some_df = sqlContext.createDataFrame(some_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema\n",
    "schema = StructType([StructField('personal_name', StringType(), False),\n",
    "                    StructField('age', IntegerType(), False)])\n",
    "another_df = sqlContext.createDataFrame(some_rdd, schema)\n",
    "# another_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from other type of files\n",
    "# read from pandas\n",
    "import pandas as pd\n",
    "pd_df = sqlContext.createDataFrame(pd.DataFrame(range(5)))\n",
    "# or \n",
    "pd_df = spark.createDataFrame(pd.DataFrame(range(5)))\n",
    "# pd_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from json\n",
    "import json\n",
    "data = [ { 'a' : 1, 'b' : 2, 'c' : 3, 'd' : 4, 'e' : 5 } ]\n",
    "with open('test_data.json', 'w') as add:\n",
    "    json.dump(data, add)\n",
    "json_df = sqlContext.read.json('test_data.json')\n",
    "# or \n",
    "json_df = spark.read.json('test_data.json')\n",
    "# json_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from csv\n",
    "csv_df = spark.read.csv('titanic.csv', header = True)\n",
    "# csv_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from parquet\n",
    "parquet_df = spark.read.load('part-00000-82db5734-5b30-4b12-8c75-3d0197e2f1b0-c000.snappy.parquet')\n",
    "# parquet_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to parquet\n",
    "# csv_df.write.parquet(\"titanic.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+-------+---+-----+-----+-----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+--------+------+------+--------+\n",
      "|Passengerid|Age|   Fare|Sex|sibsp|zero5|zero6|zero7|zero8|zero9|zero10|zero11|Parch|zero13|zero14|zero15|zero16|zero17|zero18|zero19|zero20|Pclass|zero22|zero23|Embarked|zero25|zero26|2urvived|\n",
      "+-----------+---+-------+---+-----+-----+-----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+--------+------+------+--------+\n",
      "|          1| 22|   7.25|  0|    1|    0|    0|    0|    0|    0|     0|     0|    0|     0|     0|     0|     0|     0|     0|     0|     0|     3|     0|     0|       2|     0|     0|       0|\n",
      "|          2| 38|71.2833|  1|    1|    0|    0|    0|    0|    0|     0|     0|    0|     0|     0|     0|     0|     0|     0|     0|     0|     1|     0|     0|       0|     0|     0|       1|\n",
      "|          3| 26|  7.925|  1|    0|    0|    0|    0|    0|    0|     0|     0|    0|     0|     0|     0|     0|     0|     0|     0|     0|     3|     0|     0|       2|     0|     0|       1|\n",
      "|          4| 35|   53.1|  1|    1|    0|    0|    0|    0|    0|     0|     0|    0|     0|     0|     0|     0|     0|     0|     0|     0|     1|     0|     0|       2|     0|     0|       1|\n",
      "|          5| 35|   8.05|  0|    0|    0|    0|    0|    0|    0|     0|     0|    0|     0|     0|     0|     0|     0|     0|     0|     0|     3|     0|     0|       2|     0|     0|       0|\n",
      "+-----------+---+-------+---+-----+-----+-----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+--------+------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check some row\n",
    "csv_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Passengerid: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- sibsp: string (nullable = true)\n",
      " |-- zero5: string (nullable = true)\n",
      " |-- zero6: string (nullable = true)\n",
      " |-- zero7: string (nullable = true)\n",
      " |-- zero8: string (nullable = true)\n",
      " |-- zero9: string (nullable = true)\n",
      " |-- zero10: string (nullable = true)\n",
      " |-- zero11: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- zero13: string (nullable = true)\n",
      " |-- zero14: string (nullable = true)\n",
      " |-- zero15: string (nullable = true)\n",
      " |-- zero16: string (nullable = true)\n",
      " |-- zero17: string (nullable = true)\n",
      " |-- zero18: string (nullable = true)\n",
      " |-- zero19: string (nullable = true)\n",
      " |-- zero20: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- zero22: string (nullable = true)\n",
      " |-- zero23: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- zero25: string (nullable = true)\n",
      " |-- zero26: string (nullable = true)\n",
      " |-- 2urvived: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print schema\n",
    "csv_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take\n",
    "aaa = csv_df.take(5)\n",
    "type(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to rdd\n",
    "df_rdd = csv_df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count\n",
    "csv_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Passengerid: string, Age: string, Fare: string, Sex: string, sibsp: string, zero5: string, zero6: string, zero7: string, zero8: string, zero9: string, zero10: string, zero11: string, Parch: string, zero13: string, zero14: string, zero15: string, zero16: string, zero17: string, zero18: string, zero19: string, zero20: string, Pclass: string, zero22: string, zero23: string, Embarked: string, zero25: string, zero26: string, 2urvived: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is null\n",
    "from pyspark.sql.functions import isnull\n",
    "csv_df.filter(isnull(\"Age\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               sex|\n",
      "+-------+------------------+\n",
      "|  count|              1309|\n",
      "|   mean|0.3559969442322384|\n",
      "| stddev|0.4789972834413279|\n",
      "|    min|                 0|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# describe\n",
    "csv_df.select('sex').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distinct\n",
    "csv_df.select('sex').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample\n",
    "csv_df.sample(.5).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns\n",
    "type(csv_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manipunate DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Passengerid: string, Sex: string]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select columns\n",
    "# direct (class cloumn)\n",
    "df.Passengerid \n",
    "# by Colname (class dataframe)\n",
    "df.select('Passengerid')\n",
    "df.select(df['Passengerid'], df['Sex']+1)\n",
    "df.select(df.Passengerid, df.Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Passengerid: string, Age: string, Fare: string, Sex: string, sibsp: string, zero5: string, zero6: string, zero7: string, zero8: string, zero9: string, zero10: string, zero11: string, Parch: string, zero13: string, zero14: string, zero15: string, zero16: string, zero17: string, zero18: string, zero19: string, zero20: string, Pclass: string, zero22: string, zero23: string, Embarked: string, zero25: string, zero26: string, 2urvived: string]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select with some restrictions\n",
    "df.where(\"Passengerid == '1' and Sex = '1'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Passengerid: string, Age: string, Fare: string, Sex: string, sibsp: string, zero5: string, zero6: string, zero7: string, zero8: string, zero9: string, zero10: string, zero11: string, Parch: string, zero13: string, zero14: string, zero15: string, zero16: string, zero17: string, zero18: string, zero19: string, zero20: string, Pclass: string, zero22: string, zero23: string, Embarked: string, zero25: string, zero26: string, 2urvived: string]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(\"Sex\")\n",
    "df.orderBy(df.Sex.asc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add and change column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----+---+-----+-----+-----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+--------+------+------+--------+----+\n",
      "|Passengerid|Age|Fare|Sex|sibsp|zero5|zero6|zero7|zero8|zero9|zero10|zero11|Parch|zero13|zero14|zero15|zero16|zero17|zero18|zero19|zero20|Pclass|zero22|zero23|Embarked|zero25|zero26|2urvived|Sex2|\n",
      "+-----------+---+----+---+-----+-----+-----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+--------+------+------+--------+----+\n",
      "|          1| 22|7.25|  0|    1|    0|    0|    0|    0|    0|     0|     0|    0|     0|     0|     0|     0|     0|     0|     0|     0|     3|     0|     0|       2|     0|     0|       0| 2.0|\n",
      "+-----------+---+----+---+-----+-----+-----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+--------+------+------+--------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Sex2\", 2 + df.Sex).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----+---+-----+-----+-----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+--------+------+------+--------+\n",
      "|Passengerid|Age|Fare|Sex|sibsp|zero5|zero6|zero7|zero8|zero9|zero10|zero11|Parch|zero13|zero14|zero15|zero16|zero17|zero18|zero19|zero20|Pclass|zero22|zero23|Embarked|zero25|zero26|2urvived|\n",
      "+-----------+---+----+---+-----+-----+-----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+--------+------+------+--------+\n",
      "|          1| 22|7.25|  1|    1|    0|    0|    0|    0|    0|     0|     0|    0|     0|     0|     0|     0|     0|     0|     0|     0|     3|     0|     0|       2|     0|     0|       0|\n",
      "+-----------+---+----+---+-----+-----+-----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+--------+------+------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Sex\", df.sibsp).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----+----+-----+-----+-----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+--------+------+------+--------+\n",
      "|Passengerid|Age|Fare|SSex|sibsp|zero5|zero6|zero7|zero8|zero9|zero10|zero11|Parch|zero13|zero14|zero15|zero16|zero17|zero18|zero19|zero20|Pclass|zero22|zero23|Embarked|zero25|zero26|2urvived|\n",
      "+-----------+---+----+----+-----+-----+-----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+--------+------+------+--------+\n",
      "|          1| 22|7.25|   0|    1|    0|    0|    0|    0|    0|     0|     0|    0|     0|     0|     0|     0|     0|     0|     0|     0|     3|     0|     0|       2|     0|     0|       0|\n",
      "+-----------+---+----+----+-----+-----+-----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+--------+------+------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed( \"Sex\" , \"SSex\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union (union rows and through column number!)\n",
    "csv_df.select('Sex', 'Passengerid').union(csv_df.select('Fare', 'Age')).count() # doubles the number"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
